{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PiyaleN/-demo_wbs2/blob/main/Lecture2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Processing"
      ],
      "metadata": {
        "id": "mcDV8lrlsb_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk"
      ],
      "metadata": {
        "id": "eTsD-Rfxs8Cf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer, SnowballStemmer"
      ],
      "metadata": {
        "id": "jfLT5lbXtF1H"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download extra packages"
      ],
      "metadata": {
        "id": "pCRPyADTtSb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "XYprK53utM0_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c75ce6d-6816-4375-c1d4-657d23af7617"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read the file"
      ],
      "metadata": {
        "id": "22gQuGdMzvjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/RDGopal/IB9CW0-Text-Analytics/main/Data/sms_spam.csv')"
      ],
      "metadata": {
        "id": "ysli7eIXzy4e"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "TOLK7hEF1FoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accessing files from Github"
      ],
      "metadata": {
        "id": "tJYBZX-nBS08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def list_github_directory(user, repo, path):\n",
        "    url = f\"https://api.github.com/repos/{user}/{repo}/contents/{path}\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        content = response.json()\n",
        "        return [file['name'] for file in content if file['type'] == 'file']\n",
        "    else:\n",
        "        print(\"Failed to retrieve data:\", response.status_code)\n",
        "        return []\n",
        "\n",
        "# Usage\n",
        "user = 'RDGopal'\n",
        "repo = 'IB9CW0-Text-Analytics'\n",
        "path = 'Data'\n",
        "files = list_github_directory(user, repo, path)\n",
        "print(\"Files in the Data folder:\", files)\n"
      ],
      "metadata": {
        "id": "NnoVbw6BBXfz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "392157e2-c242-41bd-bcbd-5b886f67574c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in the Data folder: ['26k-consumer-complaints.csv', 'Headlines_5000.csv', 'Kickstarter.csv', 'Machine_stops.pdf', 'Reviews.csv', 'Roomba.csv', 'Tweets.csv', 'disaster_tweets.csv', 'docAI.pdf', 'fakenews.csv', 'financial_news.csv', 'imdb.csv', 'oct_delta.csv', 'pyschology.csv', 'sms_spam.csv', 'tinyshakespeare.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "nHGy52Uv1ljt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lowercase\n",
        "df['text'] = df['text'].str.lower()"
      ],
      "metadata": {
        "id": "qKvtHACE1qlN"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize\n",
        "df['tokens'] = df['text'].apply(nltk.word_tokenize)"
      ],
      "metadata": {
        "id": "lzn7m_R15Sqt"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get stopwords from nltk\n",
        "stop_words = stopwords.words('english')\n",
        "extra_words = ['.','*',',']\n",
        "stop_words.extend(extra_words)"
      ],
      "metadata": {
        "id": "hen-yoKZ5pkF"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words"
      ],
      "metadata": {
        "id": "6bSyifq8S9sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove stopwords and remove the alpha numeric tokens\n",
        "df['tokens'] = df['tokens'].apply(lambda tokens: [token for token in tokens if token not in stop_words and token.isalpha()])"
      ],
      "metadata": {
        "id": "CiMxr6Bu-NT1"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a PorterStemmer object - stemming is a process of reducing a word to its root\n",
        "stemmer = PorterStemmer()  # porters stemmer is the default stemmer in nltk nut it depends on us whether you want to use it or not. if we want to do sentiment analyis we don't want to use porter stemmer\n",
        "df['tokens'] = df['tokens'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])"
      ],
      "metadata": {
        "id": "9dGi1FVz-tTV"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatize\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "df['tokens'] = df['tokens'].apply(lambda tokens: [lemmatizer.lemmatize(token) for token in tokens])\n"
      ],
      "metadata": {
        "id": "Lfz9iht_-891"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "B-agi41pdSyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine tokens back into a cleaned review\n",
        "df['text1'] = df['tokens'].apply(lambda tokens: ' '.join(tokens))"
      ],
      "metadata": {
        "id": "3ssLzou3_Yx1"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['text','text1']]"
      ],
      "metadata": {
        "id": "4yFdrmFB_rwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Put it all into a function\n",
        "def preprocess_text(text):\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Tokenize\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    # Remove stopwords\n",
        "    stop_words = stopwords.words('english')\n",
        "    extra_words = ['.','*',',']\n",
        "    stop_words.extend(extra_words)\n",
        "    tokens = [token for token in tokens if token not in stop_words and token.isalpha()]\n",
        "    # Lemmatize\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return ' '.join(tokens)"
      ],
      "metadata": {
        "id": "-ca8XWqCEzb1"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df['tokens'] = df['text'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "-aicK2tZEbLU"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "rRgQRr64X_ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Your Turn\n",
        "Read and preprocess the file `oct_delta.csv`"
      ],
      "metadata": {
        "id": "aGGA0DpUHRGM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bag-of-Words and tf-idf"
      ],
      "metadata": {
        "id": "cJez0UcIFf5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import LdaModel,CoherenceModel,TfidfModel,Nmf,LsiModel"
      ],
      "metadata": {
        "id": "POsQsoJ4Fp3l"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create list of tokens\n",
        "documents = df['tokens'].tolist()"
      ],
      "metadata": {
        "id": "WWoTnFRgFsAS"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents"
      ],
      "metadata": {
        "id": "784Z59uMF4Qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the dictionary\n",
        "dictionary = Dictionary(documents) # list of lists (documents)"
      ],
      "metadata": {
        "id": "7_amKNStGJs0"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional if want to see the dictionary\n",
        "dictionary.save_as_text('testxyz.csv',sort_by_word=True)"
      ],
      "metadata": {
        "id": "VWcvS4nZGLfz"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filter extremes from the dictionary (optional, but recommended)\n",
        "dictionary.filter_extremes(no_below=5, no_above=0.5) # at least appears in 5 documents, no more than 50%"
      ],
      "metadata": {
        "id": "zSN_KP9PHx8j"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create bag-of-words representation\n",
        "corpus = [dictionary.doc2bow(document) for document in documents]"
      ],
      "metadata": {
        "id": "Ac1RV8wVH9_z"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "id": "CtoHhe3rID_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create tf-idf representation\n",
        "tfidf_model = TfidfModel(corpus)\n",
        "tfidf_corpus = [tfidf_model[doc] for doc in corpus]"
      ],
      "metadata": {
        "id": "P7bpSUzcISSU"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_corpus"
      ],
      "metadata": {
        "id": "itbQf-3DIW07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Frequency Analysis"
      ],
      "metadata": {
        "id": "lFGhVIaYx87X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib wordcloud\n"
      ],
      "metadata": {
        "id": "18kZkWaWyAI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To perform frequency analysis, we need to count how often each word appears in your corpus. We can utilize the dictionary and the Bag-of-Words (BoW) corpus"
      ],
      "metadata": {
        "id": "J5eyDC9jyTUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Summing up the counts from the BoW corpus\n",
        "total_word_count = Counter(word_id for document in corpus for word_id, count in document)\n",
        "\n",
        "# Mapping back the word IDs to words\n",
        "mapped_word_counts = [(dictionary[word_id], count) for word_id, count in total_word_count.items()]\n",
        "\n",
        "# Sort words by frequency\n",
        "sorted_word_counts = sorted(mapped_word_counts, key=lambda w: w[1], reverse=True)\n",
        "\n",
        "# Let's plot the top words\n",
        "plt.figure(figsize=(10, 5))\n",
        "words, counts = zip(*sorted_word_counts[:40])\n",
        "plt.bar(words, counts)\n",
        "plt.xlabel('Words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Top 20 Words by Frequency')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "H8DZx-ZZyNaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a Word Cloud\n",
        "To create a word cloud, you will need the frequencies in a dictionary format, where the keys are words and the values are their frequencies."
      ],
      "metadata": {
        "id": "JEweScxUy_qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "# Creating a dictionary for word cloud\n",
        "word_freq_dict = dict(sorted_word_counts)\n",
        "\n",
        "# Creating word cloud\n",
        "wordcloud = WordCloud(width = 800, height = 400, background_color ='white').generate_from_frequencies(word_freq_dict)\n",
        "\n",
        "# Displaying the word cloud\n",
        "plt.figure(figsize=(15, 8))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')  # Turn off axis numbers and ticks\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-t_9AkV_zGhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Turn\n",
        "Conduct frequency analysis with `oct_delta.csv` file."
      ],
      "metadata": {
        "id": "SMxY-w0RKSfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('oct_delta.csv')"
      ],
      "metadata": {
        "id": "1FLA6x1kjroH"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "fYpNwa4Pjzmf",
        "outputId": "5b74587c-ef9f-49b9-b3d0-ecd6207d3e90"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     weekday month  date  year  \\\n",
              "0        Thu   Oct     1  2015   \n",
              "1        Thu   Oct     1  2015   \n",
              "2        Thu   Oct     1  2015   \n",
              "3        Thu   Oct     1  2015   \n",
              "4        Thu   Oct     1  2015   \n",
              "...      ...   ...   ...   ...   \n",
              "1372     Thu   Oct    15  2015   \n",
              "1373     Thu   Oct    15  2015   \n",
              "1374     Thu   Oct    15  2015   \n",
              "1375     Thu   Oct    15  2015   \n",
              "1376     Thu   Oct    15  2015   \n",
              "\n",
              "                                                   text  \n",
              "0     @mjdout I know that can be frustrating..we hop...  \n",
              "1     @rmarkerm Terribly sorry for the inconvenience...  \n",
              "2     @checho85  I can check, pls follow and DM your...  \n",
              "3     @nealaa ...Alerts, pls check here: http://t.co...  \n",
              "4     @nealaa ...advisory has only been issued for t...  \n",
              "...                                                 ...  \n",
              "1372  @satijp Woohoo! Way to go Marla and Mira! Happ...  \n",
              "1373  @lukenbaugh1 You're welcome! Have a great day!...  \n",
              "1374  @jeffcarp  If you do not make your connection,...  \n",
              "1375                        @jeffcarp ...719pm. *DD 2/2  \n",
              "1376               @svchappel That sounds yummy. :) *CM  \n",
              "\n",
              "[1377 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-11c802ac-cc6c-4032-a70f-4c4649d11743\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>weekday</th>\n",
              "      <th>month</th>\n",
              "      <th>date</th>\n",
              "      <th>year</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Thu</td>\n",
              "      <td>Oct</td>\n",
              "      <td>1</td>\n",
              "      <td>2015</td>\n",
              "      <td>@mjdout I know that can be frustrating..we hop...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Thu</td>\n",
              "      <td>Oct</td>\n",
              "      <td>1</td>\n",
              "      <td>2015</td>\n",
              "      <td>@rmarkerm Terribly sorry for the inconvenience...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Thu</td>\n",
              "      <td>Oct</td>\n",
              "      <td>1</td>\n",
              "      <td>2015</td>\n",
              "      <td>@checho85  I can check, pls follow and DM your...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Thu</td>\n",
              "      <td>Oct</td>\n",
              "      <td>1</td>\n",
              "      <td>2015</td>\n",
              "      <td>@nealaa ...Alerts, pls check here: http://t.co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Thu</td>\n",
              "      <td>Oct</td>\n",
              "      <td>1</td>\n",
              "      <td>2015</td>\n",
              "      <td>@nealaa ...advisory has only been issued for t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1372</th>\n",
              "      <td>Thu</td>\n",
              "      <td>Oct</td>\n",
              "      <td>15</td>\n",
              "      <td>2015</td>\n",
              "      <td>@satijp Woohoo! Way to go Marla and Mira! Happ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1373</th>\n",
              "      <td>Thu</td>\n",
              "      <td>Oct</td>\n",
              "      <td>15</td>\n",
              "      <td>2015</td>\n",
              "      <td>@lukenbaugh1 You're welcome! Have a great day!...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1374</th>\n",
              "      <td>Thu</td>\n",
              "      <td>Oct</td>\n",
              "      <td>15</td>\n",
              "      <td>2015</td>\n",
              "      <td>@jeffcarp  If you do not make your connection,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1375</th>\n",
              "      <td>Thu</td>\n",
              "      <td>Oct</td>\n",
              "      <td>15</td>\n",
              "      <td>2015</td>\n",
              "      <td>@jeffcarp ...719pm. *DD 2/2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1376</th>\n",
              "      <td>Thu</td>\n",
              "      <td>Oct</td>\n",
              "      <td>15</td>\n",
              "      <td>2015</td>\n",
              "      <td>@svchappel That sounds yummy. :) *CM</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1377 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11c802ac-cc6c-4032-a70f-4c4649d11743')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-11c802ac-cc6c-4032-a70f-4c4649d11743 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-11c802ac-cc6c-4032-a70f-4c4649d11743');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-648c4717-6d95-4644-9b2a-014691261c6c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-648c4717-6d95-4644-9b2a-014691261c6c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-648c4717-6d95-4644-9b2a-014691261c6c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1377,\n  \"fields\": [\n    {\n      \"column\": \"weekday\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Thu\",\n          \"Fri\",\n          \"Tue\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Oct\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 1,\n        \"max\": 15,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2015,\n        \"max\": 2015,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2015\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1377,\n        \"samples\": [\n          \"@JeremyMerrill Understandable. Hope you make it for the event.  *PL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Pre processing"
      ],
      "metadata": {
        "id": "g8ENo9GZkAtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lowercase\n",
        "df['text'] = df['text'].str.lower()"
      ],
      "metadata": {
        "id": "QU1VQj2Oj_Uo"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize\n",
        "df['tokens'] = df['text'].apply(nltk.word_tokenize)"
      ],
      "metadata": {
        "id": "pWjtLaYHkLvT"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get stopwords from nltk\n",
        "stop_words = stopwords.words('english')\n",
        "extra_words = ['.','*',',']\n",
        "stop_words.extend(extra_words)"
      ],
      "metadata": {
        "id": "LVNMY_B_mKO6"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove stopwords and remove the alpha numeric tokens\n",
        "df['tokens'] = df['tokens'].apply(lambda tokens: [token for token in tokens if token not in stop_words and token.isalpha()])"
      ],
      "metadata": {
        "id": "iGnvHbqbmJ_5"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a PorterStemmer object - stemming is a process of reducing a word to its root\n",
        "stemmer = PorterStemmer()  # porters stemmer is the default stemmer in nltk nut it depends on us whether you want to use it or not. if we want to do sentiment analyis we don't want to use porter stemmer\n",
        "df['tokens'] = df['tokens'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])"
      ],
      "metadata": {
        "id": "yCXhK4LtmJ0I"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatize\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "df['tokens'] = df['tokens'].apply(lambda tokens: [lemmatizer.lemmatize(token) for token in tokens])"
      ],
      "metadata": {
        "id": "_U2QePJSmJoA"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine tokens back into a cleaned review\n",
        "df['text1'] = df['tokens'].apply(lambda tokens: ' '.join(tokens))"
      ],
      "metadata": {
        "id": "aw8DzLXsmI9c"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df['tokens'] = df['text'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "hNahoFV_mrfC"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "ypmkxYPWm4WT",
        "outputId": "4a4fc9f9-cb00-49e0-a0eb-748f4fd6faf1"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     weekday month  date  year  \\\n",
              "0        Thu   Oct     1  2015   \n",
              "1        Thu   Oct     1  2015   \n",
              "2        Thu   Oct     1  2015   \n",
              "3        Thu   Oct     1  2015   \n",
              "4        Thu   Oct     1  2015   \n",
              "...      ...   ...   ...   ...   \n",
              "1372     Thu   Oct    15  2015   \n",
              "1373     Thu   Oct    15  2015   \n",
              "1374     Thu   Oct    15  2015   \n",
              "1375     Thu   Oct    15  2015   \n",
              "1376     Thu   Oct    15  2015   \n",
              "\n",
              "                                                   text  \\\n",
              "0     @mjdout i know that can be frustrating..we hop...   \n",
              "1     @rmarkerm terribly sorry for the inconvenience...   \n",
              "2     @checho85  i can check, pls follow and dm your...   \n",
              "3     @nealaa ...alerts, pls check here: http://t.co...   \n",
              "4     @nealaa ...advisory has only been issued for t...   \n",
              "...                                                 ...   \n",
              "1372  @satijp woohoo! way to go marla and mira! happ...   \n",
              "1373  @lukenbaugh1 you're welcome! have a great day!...   \n",
              "1374  @jeffcarp  if you do not make your connection,...   \n",
              "1375                        @jeffcarp ...719pm. *dd 2/2   \n",
              "1376               @svchappel that sounds yummy. :) *cm   \n",
              "\n",
              "                                                 tokens  \\\n",
              "0     mjdout know frustrating hope parked deplaned s...   \n",
              "1     rmarkerm terribly sorry inconvenience assistan...   \n",
              "2            check pls follow dm confirmation review aa   \n",
              "3                        nealaa alert pls check http jh   \n",
              "4     nealaa advisory issued bahamas could change ch...   \n",
              "...                                                 ...   \n",
              "1372    satijp woohoo way go marla mira happy travel dd   \n",
              "1373                               welcome great day rd   \n",
              "1374  jeffcarp make connection gate agent advise opt...   \n",
              "1375                                        jeffcarp dd   \n",
              "1376                           svchappel sound yummy cm   \n",
              "\n",
              "                                                  text1  \n",
              "0     mjdout know frustrat hope park deplan shortli ...  \n",
              "1     rmarkerm terribl sorri inconveni assist time p...  \n",
              "2                  check pl follow dm confirm review aa  \n",
              "3                         nealaa alert pl check http jh  \n",
              "4     nealaa advisori issu bahama could chang check ...  \n",
              "...                                                 ...  \n",
              "1372    satijp woohoo way go marla mira happi travel dd  \n",
              "1373                                welcom great day rd  \n",
              "1374  jeffcarp make connect gate agent advis option ...  \n",
              "1375                                        jeffcarp dd  \n",
              "1376                           svchappel sound yummi cm  \n",
              "\n",
              "[1377 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43dc7fab-e9b7-4a03-b9d4-71d239744450\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>weekday</th>\n",
              "      <th>month</th>\n",
              "      <th>date</th>\n",
              "      <th>year</th>\n",
              "      <th>text</th>\n",
              "      <th>tokens</th>\n",
              "      <th>text1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Thu</td>\n",
              "      <td>Oct</td>\n",
              "      <td>1</td>\n",
              "      <td>2015</td>\n",
              "      <td>@mjdout i know that can be frustrating..we hop...</td>\n",
              "      <td>mjdout know frustrating hope parked deplaned s...</td>\n",
              "      <td>mjdout know frustrat hope park deplan shortli ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Thu</td>\n",
              "      <td>Oct</td>\n",
              "      <td>1</td>\n",
              "      <td>2015</td>\n",
              "      <td>@rmarkerm terribly sorry for the inconvenience...</td>\n",
              "      <td>rmarkerm terribly sorry inconvenience assistan...</td>\n",
              "      <td>rmarkerm terribl sorri inconveni assist time p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Thu</td>\n",
              "      <td>Oct</td>\n",
              "      <td>1</td>\n",
              "      <td>2015</td>\n",
              "      <td>@checho85  i can check, pls follow and dm your...</td>\n",
              "      <td>check pls follow dm confirmation review aa</td>\n",
              "      <td>check pl follow dm confirm review aa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Thu</td>\n",
              "      <td>Oct</td>\n",
              "      <td>1</td>\n",
              "      <td>2015</td>\n",
              "      <td>@nealaa ...alerts, pls check here: http://t.co...</td>\n",
              "      <td>nealaa alert pls check http jh</td>\n",
              "      <td>nealaa alert pl check http jh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Thu</td>\n",
              "      <td>Oct</td>\n",
              "      <td>1</td>\n",
              "      <td>2015</td>\n",
              "      <td>@nealaa ...advisory has only been issued for t...</td>\n",
              "      <td>nealaa advisory issued bahamas could change ch...</td>\n",
              "      <td>nealaa advisori issu bahama could chang check ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1372</th>\n",
              "      <td>Thu</td>\n",
              "      <td>Oct</td>\n",
              "      <td>15</td>\n",
              "      <td>2015</td>\n",
              "      <td>@satijp woohoo! way to go marla and mira! happ...</td>\n",
              "      <td>satijp woohoo way go marla mira happy travel dd</td>\n",
              "      <td>satijp woohoo way go marla mira happi travel dd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1373</th>\n",
              "      <td>Thu</td>\n",
              "      <td>Oct</td>\n",
              "      <td>15</td>\n",
              "      <td>2015</td>\n",
              "      <td>@lukenbaugh1 you're welcome! have a great day!...</td>\n",
              "      <td>welcome great day rd</td>\n",
              "      <td>welcom great day rd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1374</th>\n",
              "      <td>Thu</td>\n",
              "      <td>Oct</td>\n",
              "      <td>15</td>\n",
              "      <td>2015</td>\n",
              "      <td>@jeffcarp  if you do not make your connection,...</td>\n",
              "      <td>jeffcarp make connection gate agent advise opt...</td>\n",
              "      <td>jeffcarp make connect gate agent advis option ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1375</th>\n",
              "      <td>Thu</td>\n",
              "      <td>Oct</td>\n",
              "      <td>15</td>\n",
              "      <td>2015</td>\n",
              "      <td>@jeffcarp ...719pm. *dd 2/2</td>\n",
              "      <td>jeffcarp dd</td>\n",
              "      <td>jeffcarp dd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1376</th>\n",
              "      <td>Thu</td>\n",
              "      <td>Oct</td>\n",
              "      <td>15</td>\n",
              "      <td>2015</td>\n",
              "      <td>@svchappel that sounds yummy. :) *cm</td>\n",
              "      <td>svchappel sound yummy cm</td>\n",
              "      <td>svchappel sound yummi cm</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1377 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43dc7fab-e9b7-4a03-b9d4-71d239744450')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-43dc7fab-e9b7-4a03-b9d4-71d239744450 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-43dc7fab-e9b7-4a03-b9d4-71d239744450');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bb8166d9-6cee-42a1-a5b0-a547d9353bea\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bb8166d9-6cee-42a1-a5b0-a547d9353bea')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bb8166d9-6cee-42a1-a5b0-a547d9353bea button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1377,\n  \"fields\": [\n    {\n      \"column\": \"weekday\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"Thu\",\n          \"Fri\",\n          \"Tue\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Oct\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 1,\n        \"max\": 15,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2015,\n        \"max\": 2015,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2015\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1377,\n        \"samples\": [\n          \"@jeremymerrill understandable. hope you make it for the event.  *pl\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1372,\n        \"samples\": [\n          \"tendrid hi sorry delayed response help sd\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1371,\n        \"samples\": [\n          \"tendrid hi sorri delay respons help sd\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import LdaModel,CoherenceModel,TfidfModel,Nmf,LsiModel"
      ],
      "metadata": {
        "id": "Ou5FshZKnBLG"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create list of tokens\n",
        "documents = df['tokens'].tolist()"
      ],
      "metadata": {
        "id": "MeLLNkzTnIEE"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the dictionary\n",
        "dictionary = Dictionary(documents) # list of lists (documents)"
      ],
      "metadata": {
        "id": "ktuWiPN2nSNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional if want to see the dictionary\n",
        "dictionary.save_as_text('testxyz.csv',sort_by_word=True)"
      ],
      "metadata": {
        "id": "Tm53CZ03nkbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**complete this **"
      ],
      "metadata": {
        "id": "w3FpzvjHolpQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tiny Shakespeare novel"
      ],
      "metadata": {
        "id": "xO8hZeCr2fxD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read the file locally"
      ],
      "metadata": {
        "id": "F_vddh2JFG7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load the text file\n",
        "with open('/content/tinyshakespeare.txt', 'r') as file:\n",
        "    text = file.read().lower()\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text)\n"
      ],
      "metadata": {
        "id": "6IKd9lig2os_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Or Read the file from GitHub"
      ],
      "metadata": {
        "id": "GswT33ABFK7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import requests\n",
        "\n",
        "# URL to the raw text file on GitHub\n",
        "url = 'https://raw.githubusercontent.com/RDGopal/IB9CW0-Text-Analytics/main/Data/tinyshakespeare.txt'\n",
        "\n",
        "# Use requests to get the content of the file\n",
        "response = requests.get(url)\n",
        "\n",
        "# Ensure the request was successful\n",
        "if response.status_code == 200:\n",
        "    text = response.text.lower()\n",
        "    # Continue processing the text as needed\n",
        "else:\n",
        "    print(\"Failed to retrieve the file. Status code:\", response.status_code)\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text)"
      ],
      "metadata": {
        "id": "48_gKi3iEKpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokens)"
      ],
      "metadata": {
        "id": "xmpZvKm52v1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zipf's Law\n",
        "\n",
        "Zipf's Law is an empirical law that suggests the frequency of a word in a natural language text is inversely proportional to its rank in the frequency table. To test Zipf's Law with your tokenized text data, we follow the steps below:\n",
        "\n",
        "1. **Calculate Word Frequencies**: Count how often each word appears in your tokenized text.\n",
        "\n",
        "2. **Sort Words by Frequency**: Rank the words by their frequency in descending order.\n",
        "\n",
        "3. **Plot the Frequencies**: Plot the frequency of each word against its rank on a log-log plot.\n",
        "\n",
        "4. **Analyze the Plot**: Zipf's Law predicts a linear relationship on a log-log plot with a slope of approximately -1.\n"
      ],
      "metadata": {
        "id": "JhkYl1iXGC9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "# Count frequencies\n",
        "word_counts = Counter(tokens)\n",
        "\n",
        "# Sort words by frequency\n",
        "sorted_word_counts = word_counts.most_common()\n",
        "\n",
        "# Prepare data for plotting\n",
        "ranks = range(1, len(sorted_word_counts) + 1)\n",
        "frequencies = [freq for _, freq in sorted_word_counts]\n",
        "\n",
        "# Log-log plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.loglog(ranks, frequencies, marker=\"o\")\n",
        "plt.title('Zipf\\'s Law')\n",
        "plt.xlabel('Rank of the word')\n",
        "plt.ylabel('Frequency of the word')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wLlP-MXPGHsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get English stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Remove stopwords from tokens\n",
        "filtered_tokens = [token for token in tokens if token not in stop_words and token.isalpha()]\n"
      ],
      "metadata": {
        "id": "fsPogqVZ20m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(filtered_tokens)"
      ],
      "metadata": {
        "id": "BqhMHoTh29fW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Count word frequencies\n",
        "word_counts = Counter(filtered_tokens)\n"
      ],
      "metadata": {
        "id": "D6PA1qlu3Xnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_counts"
      ],
      "metadata": {
        "id": "lNK67sFj3aHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a word cloud\n",
        "wordcloud = WordCloud(width = 800, height = 400, background_color ='white').generate_from_frequencies(word_counts)\n",
        "\n",
        "# Display the word cloud\n",
        "plt.figure(figsize=(15, 8))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')  # Turn off axis numbers and ticks\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "f_aFueIs3k_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the 20 most common words\n",
        "most_common_words = word_counts.most_common(20)\n",
        "\n",
        "# Unpack the words and their frequencies\n",
        "words, frequencies = zip(*most_common_words)\n",
        "\n",
        "# Create a bar chart\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.bar(words, frequencies)\n",
        "plt.xlabel('Words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Top 20 Most Frequent Words')\n",
        "plt.xticks(rotation=45)  # Rotate the words on x-axis to avoid overlapping\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eRVInZzs36IT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Turn\n",
        "Run the following code to get a novel from HugginFace and conduct Zipf's law analysis."
      ],
      "metadata": {
        "id": "8c0SHY2sKiPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import requests\n",
        "\n",
        "# URL to the raw text file on GitHub\n",
        "url =\"https://datasets-server.huggingface.co/rows?dataset=JiggaBooJombs%2FNovelist&config=default&split=train&offset=0&length=100\"\n",
        "\n",
        "# Use requests to get the content of the file\n",
        "response = requests.get(url)\n",
        "\n",
        "# Ensure the request was successful\n",
        "if response.status_code == 200:\n",
        "    text = response.text.lower()\n",
        "    # Continue processing the text as needed\n",
        "else:\n",
        "    print(\"Failed to retrieve the file. Status code:\", response.status_code)\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text)"
      ],
      "metadata": {
        "id": "JEQIJ_qqKjky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# POS Tagging"
      ],
      "metadata": {
        "id": "kooyfJGl1Rck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "rDxee82w60Ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# POS tagging the filtered tokens\n",
        "pos_tags = nltk.pos_tag(filtered_tokens)\n",
        "\n",
        "# Count word frequencies (including the POS tags for uniqueness)\n",
        "word_counts = Counter(pos_tags)\n",
        "\n",
        "# Create a list of dictionaries to later convert to a DataFrame\n",
        "data = [{'Word': word, 'POS': pos, 'WordCount': count} for (word, pos), count in word_counts.items()]\n",
        "\n",
        "# Create the DataFrame\n",
        "df_pos = pd.DataFrame(data)\n",
        "\n",
        "# Display the first few rows of the DataFrame to verify\n",
        "print(df_pos.head())"
      ],
      "metadata": {
        "id": "09yMxD0-1TdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create POS mapping"
      ],
      "metadata": {
        "id": "s513SrJJE5Az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_tag_full_form = {\n",
        "    'CC': 'Coordinating conjunction',\n",
        "    'CD': 'Cardinal number',\n",
        "    'DT': 'Determiner',\n",
        "    'EX': 'Existential there',\n",
        "    'FW': 'Foreign word',\n",
        "    'IN': 'Preposition or subordinating conjunction',\n",
        "    'JJ': 'Adjective',\n",
        "    'JJR': 'Adjective, comparative',\n",
        "    'JJS': 'Adjective, superlative',\n",
        "    'LS': 'List item marker',\n",
        "    'MD': 'Modal',\n",
        "    'NN': 'Noun, singular or mass',\n",
        "    'NNS': 'Noun, plural',\n",
        "    'NNP': 'Proper noun, singular',\n",
        "    'NNPS': 'Proper noun, plural',\n",
        "    'PDT': 'Predeterminer',\n",
        "    'POS': 'Possessive ending',\n",
        "    'PRP': 'Personal pronoun',\n",
        "    'PRP$': 'Possessive pronoun',\n",
        "    'RB': 'Adverb',\n",
        "    'RBR': 'Adverb, comparative',\n",
        "    'RBS': 'Adverb, superlative',\n",
        "    'RP': 'Particle',\n",
        "    'SYM': 'Symbol',\n",
        "    'TO': 'to',\n",
        "    'UH': 'Interjection',\n",
        "    'VB': 'Verb, base form',\n",
        "    'VBD': 'Verb, past tense',\n",
        "    'VBG': 'Verb, gerund or present participle',\n",
        "    'VBN': 'Verb, past participle',\n",
        "    'VBP': 'Verb, non-3rd person singular present',\n",
        "    'VBZ': 'Verb, 3rd person singular present',\n",
        "    'WDT': 'Wh-determiner',\n",
        "    'WP': 'Wh-pronoun',\n",
        "    'WP$': 'Possessive wh-pronoun',\n",
        "    'WRB': 'Wh-adverb'\n",
        "}\n"
      ],
      "metadata": {
        "id": "2WrbNXVRE72i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pos['POS Full Form'] = df_pos['POS'].map(pos_tag_full_form)\n",
        "\n",
        "# Display the DataFrame with the new column\n",
        "print(df_pos.head())"
      ],
      "metadata": {
        "id": "OmsOqYHXE-UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count total occurrences of words for each POS tag\n",
        "pos_total_counts = df_pos.groupby('POS').size()\n",
        "\n",
        "# Display the total occurrences of words for each POS tag\n",
        "print(pos_total_counts)"
      ],
      "metadata": {
        "id": "1RBf-OtMF-tA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Turn\n",
        "Conduct POS analysis for `sms_spam.csv` and `oct_delta.csv` data."
      ],
      "metadata": {
        "id": "pjx8eOqNL4Ss"
      }
    }
  ]
}